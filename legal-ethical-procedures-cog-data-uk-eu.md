Legal, Ethical, and Procedural Requirements for Collecting, Publishing, and Using Normative Human Cognitive Performance Data in the UK and EU

Introduction
The collection, publication, and use of normative human cognitive performance data are foundational to psychometric research, clinical assessment, and the development of cognitive technologies. However, these activities are subject to a complex web of legal, ethical, and procedural requirements, especially within the United Kingdom (UK) and the European Union (EU). The regulatory landscape encompasses informed consent, research ethics committee (REC) or institutional review board (IRB) approvals, data protection and privacy under UK and EU General Data Protection Regulation (GDPR), data sharing and publication rules, cross-border data transfer, and guidance from professional bodies such as the British Psychological Society (BPS), Health Research Authority (HRA), Information Commissioner’s Office (ICO), and their EU counterparts.
This report provides a comprehensive analysis of these requirements, focusing on the compliance needs for large-scale normative studies such as those conducted for the calibration and validation of cognitive assessment tools like Yook. It synthesizes statutory obligations, regulatory guidance, professional standards, and practical documentation templates, culminating in a detailed compliance checklist and documentation guide. The report is structured to address each key area, integrating the latest updates and referencing authoritative sources throughout.

1. Informed Consent Language and Documentation for Psychometric Testing
1.1. UK Requirements for Informed Consent
In the UK, informed consent is a cornerstone of ethical research involving human participants, particularly in psychometric and cognitive testing. The HRA and BPS provide detailed guidance on the principles and practicalities of obtaining consent. Consent must be:
• 	Freely given: Participants must not feel coerced or unduly influenced.

• 	Specific: Consent should be for clearly defined purposes, including primary data collection and any anticipated secondary uses.

• 	Informed: Participants must receive comprehensive information about the study, including its aims, procedures, risks, benefits, data handling, and their rights.

• 	Unambiguous: Consent must be indicated through a clear affirmative action (e.g., signing a consent form).

The HRA, in collaboration with the Medical Research Council (MRC), provides online tools and templates for participant information sheets (PIS) and consent forms. These templates are designed to ensure compliance with both ethical and legal standards, including the UK GDPR. The recommended content includes:

• 	Study title and purpose

• 	What participation involves

• 	Risks and benefits

• 	Confidentiality and data protection (including GDPR transparency wording)

• 	Voluntary nature of participation and right to withdraw

• 	Contact details for queries or complaints

For studies involving children, young people, or adults lacking capacity, additional safeguards and tailored consent processes are required, as outlined in the Mental Capacity Act 2005 and related guidance.
1.2. EU Requirements for Informed Consent
The EU GDPR and the European Data Protection Board (EDPB) Guidelines 05/2020 on consent set out similar standards for informed consent in research. Key elements include:
• 	Granularity: Separate consent for different processing operations where appropriate.
• 	Transparency: Clear, plain language; layered information may be used for complex studies.
• 	Withdrawal: Participants must be informed of their right to withdraw consent at any time, without detriment.
• 	Documentation: Controllers must be able to demonstrate that valid consent was obtained.
For scientific research, Recital 33 of the GDPR allows for some flexibility where it is not possible to fully specify the research purposes at the outset, provided that consent is in line with recognized ethical standards and participants are given the opportunity to consent to certain areas or parts of research.
1.3. Consent for Data Reuse and Secondary Analysis
Both UK and EU frameworks require that consent for secondary use of data (e.g., for future research, data sharing, or AI training) be explicit and specific. Where secondary uses are not fully defined at the time of collection, broad consent may be acceptable if accompanied by robust safeguards and ongoing transparency. However, controllers must ensure that any new processing is compatible with the original consent or seek fresh consent as needed.
1.4. Documentation Templates
The HRA and IRAS provide up-to-date templates for consent forms and participant information sheets, incorporating GDPR transparency wording and tailored sections for special populations. These templates are widely accepted by RECs and are expected to be used without modification unless justified.

3. Research Ethics Committee (REC/IRB) Approval Processes
2.1. UK REC Approval Process
In the UK, research involving human participants, especially in health, social care, or large-scale normative studies, requires review and approval by a REC recognized by the HRA. The process involves:
• 	Application via IRAS: Researchers complete a detailed application on the Integrated Research Application System (IRAS), including study protocol, consent documents, data management plans, and supporting materials.
• 	Validation and Booking: Applications are validated and booked for review, either through the HRA Approval route or REC-only route, depending on the study type.
• 	Proportionate vs. Full Review: Studies with minimal ethical issues may be eligible for proportionate review; others require full committee review.
• 	Decision Timeline: RECs are required to provide an opinion within 60 calendar days of a valid application.
• 	Possible Outcomes: Favourable opinion (with or without conditions), provisional opinion (requiring clarifications), or unfavourable opinion (with reasons and appeal options).
Standard conditions apply post-approval, including requirements for reporting amendments, adverse events, and maintaining compliance with data protection and participant rights.
2.2. EU Ethics Approval Processes
In EU member states, ethics review is governed by national regulations but harmonized under the Clinical Trials Regulation (EU) No 536/2014 and the Clinical Trials Directive 2001/20/EC for medicinal studies. Key features include:
• 	Single Opinion: A single ethics committee opinion per member state, delivered within 60 days.
• 	Core Documentation: Protocol, investigator brochure, consent forms, PIS, CVs, insurance, and data protection arrangements.
• 	Site-Specific Assessment: Local assessments may be required for multi-site studies.
• 	Appeals and Amendments: Procedures for appeals and substantial amendments are standardized across the EU.
For non-interventional or normative cognitive studies, national research ethics frameworks apply, often referencing the EFGCP and European Commission guidance.
2.3. Documentation and Templates
The IRAS and HRA provide comprehensive templates for supporting documents, including model agreements, confidentiality disclosures, and material transfer agreements. These are expected to be used without modification to ensure consistency and compliance.

4. Data Protection and Privacy Rules under UK GDPR and EU GDPR
3.1. Special Category Data: Cognitive and Biometric Data
Cognitive performance data, when linked to identifiable individuals, is classified as personal data. If it reveals information about health, neurodiversity, or is used for identification (e.g., biometric templates), it is considered special category data under Article 9 of the UK GDPR and EU GDPR, warranting enhanced protection.
Special category data includes:
• 	Health data (physical or mental health, including cognitive status)
• 	Biometric data (used for unique identification, e.g., facial images, voiceprints, keystroke dynamics)
• 	Genetic data
Processing such data requires both a lawful basis under Article 6 and a specific condition under Article 9 (e.g., explicit consent, scientific research with safeguards, or substantial public interest).
3.2. Data Protection Principles
Controllers must adhere to the core data protection principles:
• 	Lawfulness, fairness, and transparency
• 	Purpose limitation: Data used only for specified, explicit purposes
• 	Data minimisation: Only data necessary for the purpose is collected
• 	Accuracy: Data must be accurate and up to date
• 	Storage limitation: Data kept no longer than necessary
• 	Integrity and confidentiality: Security measures to prevent unauthorized access, loss, or damage
• 	Accountability: Controllers must demonstrate compliance.
3.3. Research Provisions and Exemptions
The UK GDPR and DPA 2018 provide specific research provisions, allowing for certain exemptions from data subject rights (e.g., right to erasure, access, rectification, restriction, objection) where compliance would seriously impair research purposes, provided appropriate safeguards are in place (e.g., pseudonymisation, data minimisation, no measures or decisions about individuals).
However, these exemptions must be applied case by case, documented, and not used as blanket justifications.
3.4. Data Minimisation, Pseudonymisation, and Anonymisation
• 	Pseudonymisation: Replacing identifiers with codes, with the key held separately. Pseudonymised data remains personal data and subject to GDPR.
• 	Anonymisation: Irreversibly removing identifiers so individuals cannot be re-identified. Truly anonymised data falls outside GDPR scope.
• 	De-identified Data: Data stripped of direct identifiers but still potentially re-identifiable; treated as personal data unless robustly anonymised.
The ICO provides detailed guidance on effective anonymisation and pseudonymisation techniques, including hashing, encryption, and tokenisation, and stresses the importance of regular risk assessments and technical/organizational measures to prevent re-identification.
3.5. Data Subject Rights and Subject Access Requests
Participants retain rights over their data, including:
• 	Right to be informed (privacy notice)
• 	Right of access (subject access request, SAR)
• 	Right to rectification, erasure, restriction, portability, and objection
Research exemptions may apply where fulfilling these rights would undermine research objectives, but controllers must justify and document such decisions, and inform data subjects accordingly.

5. Publishing and Sharing De-identified Normative Datasets
4.1. Rules for Publishing De-identified Data
Publishing normative datasets is encouraged under open science and FAIR (Findable, Accessible, Interoperable, Reusable) principles, but only if data is robustly anonymised. Key requirements include:
• 	Anonymisation: Data must be processed so individuals cannot be identified by any means reasonably likely to be used, considering all available information and the “motivated intruder” test.
• 	Risk Assessment: Regularly assess re-identification risks, especially for rare conditions or small subgroups.
• 	Documentation: Maintain records of anonymisation processes and risk assessments.
• 	Licensing: Apply clear data usage licenses (e.g., Open Government License, Creative Commons) and metadata standards.
If data cannot be fully anonymised, sharing must be controlled via data access agreements and only with authorized parties.
4.2. Sharing with Third Parties and Data Processors
When sharing de-identified or pseudonymised datasets with third parties (e.g., collaborators, data processors, cloud providers):
• 	Data Sharing Agreements (DSA): Legally binding agreements specifying purposes, security measures, restrictions on re-identification, and responsibilities.
• 	Data Processing Agreements (DPA): Required when engaging processors, detailing instructions, security, sub-processing, and breach notification.
• 	Prohibition of Re-identification: UK law criminalizes unauthorized re-identification of de-identified or pseudonymised data, with exceptions for security testing or public interest, provided notification is given.
The ICO and HRA provide model clauses and templates for DSAs and DPAs, which should be tailored to the specific context and risks.
4.3. Open Data and FAIR Principles
Adopting FAIR principles enhances data utility and compliance:
• 	Assign persistent identifiers (e.g., DOIs)
• 	Provide rich metadata and documentation
• 	Use standard vocabularies and formats
• 	Register datasets in searchable repositories
• 	Apply clear licensing and provenance information.
However, FAIRness must be balanced with privacy and data protection obligations; only truly anonymised data should be made openly accessible.

6. Cross-Border Data Transfer and Cloud Storage Compliance
5.1. Cross-Border Data Transfer Requirements
Transfers of personal data outside the UK or EU/EEA are tightly regulated:
• 	Adequacy Decisions: Transfers to countries deemed “adequate” by the UK or EU (e.g., EEA, Switzerland, Japan, South Korea, US under Data Privacy Framework) are permitted without additional safeguards.
• 	Appropriate Safeguards: For other countries, transfers require standard contractual clauses (SCCs), the UK International Data Transfer Agreement (IDTA), binding corporate rules (BCRs), or approved codes/certifications.
• 	Transfer Risk Assessment (TRA): Controllers must assess whether the destination country provides equivalent protection and implement supplementary measures if needed.
• 	Explicit Consent or Derogations: In limited cases, explicit informed consent or other exceptions may be used, but only as a last resort and with full transparency about risks.
Controllers must document all transfer mechanisms, risk assessments, and safeguards, and update privacy notices accordingly.
5.2. Cloud Storage Compliance
Storing cognitive test data in the cloud is permissible if:
• 	The cloud provider acts as a data processor under a written contract with GDPR-compliant clauses.
• 	Data is stored in the UK, EEA, or an adequate country, or appropriate safeguards are in place for other locations.
• 	Security measures (e.g., encryption, access controls, audit logs) are robust and verifiable.
• 	Data subject rights (e.g., SARs, erasure) can be facilitated.
• 	Data retention and deletion policies are enforceable, including post-contract termination.
Controllers remain responsible for ensuring ongoing compliance, even when using third-party cloud services.

7. Professional and Regulatory Guidance
6.1. British Psychological Society (BPS) and International Test Commission (ITC)
The BPS provides extensive best practice guidelines on psychometric testing, test use, communicating results, and managing neurodiversity and disability in testing contexts. Key points include:
• 	Ensuring tests are valid, reliable, and appropriate for the population
• 	Providing reasonable adjustments for neurodiverse or vulnerable participants
• 	Maintaining test security and confidentiality
• 	Following ethical standards for data collection, storage, and sharing.
The ITC offers international guidelines on computer-based testing, online assessment, and test security, which are relevant for digital cognitive studies.
6.2. Health Research Authority (HRA) and NHS Requirements
For health-related cognitive data, the HRA requires:
• 	REC approval and, where applicable, Confidentiality Advisory Group (CAG) approval for use of confidential patient information without consent
• 	Compliance with NHS Digital codes of practice for information handling
• 	Use of approved templates for agreements and documentation
• 	Adherence to the Data Protection Act 2018 and sector-specific regulations.
6.3. Information Commissioner’s Office (ICO) and EU Equivalents
The ICO is the UK’s data protection regulator, providing authoritative guidance on GDPR compliance, anonymisation, data sharing, international transfers, and research exemptions. The European Data Protection Board (EDPB) issues binding guidelines for EU GDPR interpretation and enforcement.
Controllers should regularly consult ICO and EDPB updates, especially in light of evolving legislation such as the Data (Use and Access) Act 2025 and the EU’s digital omnibus reforms.

8. AI and Algorithmic Use of Normative Cognitive Data
7.1. EU AI Act Relevance
The EU Artificial Intelligence Act (AI Act), entering into force in August 2026, imposes specific requirements on high-risk AI systems, including those using normative cognitive data for training, validation, or testing. Key obligations include:
• 	Use of high-quality, relevant, representative, and bias-mitigated datasets
• 	Robust data governance and management practices
• 	Documentation of data provenance, preparation, and bias correction measures
• 	Strict safeguards when processing special category data for bias detection/correction (e.g., technical limitations, pseudonymisation, access controls, deletion after use)
• 	Prohibition on transmitting special category data to third parties, except under strict conditions.
Controllers developing or deploying AI systems with normative cognitive data must ensure compliance with both GDPR and AI Act requirements, including DPIAs and algorithmic transparency.

9. Ethical Issues: Vulnerable Participants, Capacity, and Neurodiversity
8.1. Vulnerable Participants and Capacity
Special ethical considerations apply when research involves:
• 	Children and young people: Parental consent and age-appropriate information required; national laws may set digital consent age (typically 13–16 in EU).
• 	Adults lacking capacity: Consent from legal representatives or use of alternative lawful bases, with additional safeguards.
• 	Neurodiverse individuals: Reasonable adjustments, accessible information, and avoidance of discrimination are essential.
The BPS and HRA provide practical advice for inclusive and fair testing, emphasizing the need for proportionate and user-friendly information.
8.2. Data Protection Impact Assessments (DPIA)
A DPIA is mandatory for large-scale processing of special category data, systematic monitoring, or use of innovative technologies (e.g., AI). The DPIA must:
• 	Describe the processing, purposes, and necessity
• 	Assess risks to rights and freedoms
• 	Identify measures to mitigate risks
• 	Document consultation with stakeholders (e.g., DPO, ethics committee, affected groups).

10. Data Retention, Archiving, and Destruction Policies
Controllers must define and document:
• 	Retention periods: Data kept only as long as necessary for research purposes, subject to legal and ethical obligations.
• 	Archiving: Long-term storage for scientific or historical research may be justified, with appropriate safeguards (e.g., pseudonymisation, access controls).
• 	Destruction: Secure deletion or anonymisation when data is no longer needed, with documented procedures and audit trails.

11. Governance, International Collaboration, and Open Data
10.1. Governance Structures
Effective governance includes:
• 	Appointment of a Data Protection Officer (DPO) for large-scale or high-risk processing
• 	Regular review of policies, procedures, and compliance
• 	Training for staff and collaborators
• 	Maintenance of records of processing activities (ROPA)
10.2. International Collaboration and Post-Brexit Practicalities
EU-UK data transfers are currently permitted under adequacy decisions, but organizations must monitor for changes and be prepared to implement SCCs or IDTAs if adequacy is withdrawn. Documentation and privacy notices should reflect cross-border flows and safeguards.
10.3. Open Data and FAIR Principles
Open data publication is encouraged where possible, provided privacy is protected. The FAIR principles guide responsible sharing, maximizing research value while ensuring compliance with legal and ethical standards.

12. Compliance Checklist and Documentation Guide


11.1. Compliance Checklist Table
 
 
 

11.2. Documentation Templates and Guidance
• 	Consent Form and Participant Information Sheet: Use HRA templates, including GDPR transparency wording and sections for data reuse and withdrawal.
• 	Data Sharing Agreement (DSA): Specify purposes, security, restrictions, and responsibilities for data sharing with third parties.
• 	Data Processing Agreement (DPA): Required for processors (e.g., cloud providers), detailing instructions, security, sub-processing, and breach notification.
• 	Data Protection Impact Assessment (DPIA): Assess risks and mitigation for large-scale or high-risk processing.
• 	Privacy Notice: Clearly explain data processing, rights, transfers, and retention to participants.
• 	Records of Processing Activities (ROPA): Maintain up-to-date records as required by GDPR.
• 	Anonymisation and Pseudonymisation Policy: Document techniques, risk assessments, and review schedules.
• 	Retention and Destruction Policy: Define retention periods, archiving, and secure destruction procedures.
• 	Training and Governance Records: Document staff training, DPO appointment, and policy reviews.

12. Precedents, Case Law, and Open Data Initiatives
12.1. Precedents and Case Law
• 	The UK and EU courts have upheld the necessity of robust anonymisation for data publication, with criminal penalties for unauthorized re-identification.
• 	The National Archives and government open data initiatives provide APIs and controlled access for bulk data, subject to licensing and privacy safeguards.
12.2. Open Data and European Data Portal
• 	The European Data Portal and UK Data Service promote responsible open data sharing, with manuals and metadata standards to support compliance and interoperability.

13. Stakeholder Consultation and Further Guidance
Controllers should regularly consult:
• 	ICO: For data protection and privacy guidance, exemptions, and international transfers.
• 	HRA: For research ethics, NHS-specific requirements, and documentation templates.
• 	BPS: For psychometric testing standards, neurodiversity, and ethical practice.
• 	EDPB: For EU-wide GDPR interpretation and updates.
• 	Legal Counsel: For complex cross-border, cloud, or AI-related compliance issues.

Conclusion
The collection, publication, and use of normative human cognitive performance data in the UK and EU require meticulous attention to legal, ethical, and procedural requirements. By adhering to the principles and actions outlined in this report—grounded in statutory obligations, regulatory guidance, and professional standards—researchers and organizations can ensure robust compliance, protect participant rights, and maximize the scientific and societal value of normative cognitive data. The compliance checklist and documentation guide provided herein serve as practical tools for planning, conducting, and disseminating large-scale normative studies, such as those underpinning the calibration and validation of cognitive assessment platforms like Yook.

Appendix: Key Documentation Templates
A. Consent Form (Excerpt)
Title of Study:
Purpose:
What participation involves:
Risks and benefits:
Confidentiality and data protection:
•	Your data will be processed in accordance with the UK GDPR/EU GDPR.
•	Data may be used for future research, subject to appropriate safeguards.
•	You have the right to withdraw at any time without giving a reason.
Data sharing and publication:
•	Only anonymised data will be shared or published.
•	No identifiable information will be disclosed.
Contact for queries/complaints:
Signature:
Date:

B. Data Sharing Agreement (Excerpt)
Parties:
Purpose of data sharing:
Data description:
Security measures:
Restrictions on re-identification:
Permitted uses:
Retention and destruction:
Breach notification:
Governing law:
Signatures:

C. Data Protection Impact Assessment (DPIA) (Excerpt)
Description of processing:
Purpose and necessity:
Data categories:
Risks to rights and freedoms:
Mitigation measures:
Consultation with DPO/REC:
Outcome and actions:


For further details, consult the referenced guidance from the ICO, HRA, BPS, EDPB, and sector-specific regulatory bodies.

