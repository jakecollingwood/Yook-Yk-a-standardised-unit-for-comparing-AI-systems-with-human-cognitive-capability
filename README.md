# Yook-Yk-a-standardised-unit-for-comparing-AI-systems-with-human-cognitive-capability
Yook (Yk) is a standardised, auditable unit for comparing AI with human cognitive capability. One Yk anchors to the average adult (IQ ≈ 100). Yook reports reproducible domain sub‑scores (reasoning, memory, perception, social/emotional, creativity) and an overall score using psychometric methods. 

Yook is a standardized, auditable unit for comparing AI systems with human cognitive capability; it reports reproducible multidomain sub‑scores and an overall Yk anchored to an average adult baseline so claims about “human parity” become precise and verifiable.

Overview

Yook (Yk) is a measurement framework and unit designed to make claims about AI cognitive capability transparent, comparable, and auditable. One Yk represents a defined human baseline (publicly anchored for communication), while the scientific definition is multidomain and psychometrically grounded. Yook produces both domain sub‑scores and an aggregate Yk so strengths and weaknesses are visible.

Why Yook exists

Current capability claims are often vague, inconsistent, and non‑reproducible, which undermines trust and hampers regulation. Yook addresses this by providing a shared reference and a reproducible measurement pipeline so statements like “Model X = 1.2 Yk in reasoning; 0.8 Yk in memory” are meaningful and auditable.

Core domains

Yook measures discrete cognitive domains, each producing a sub‑score:

• Reasoning (logical, abstract, causal inference)
• Memory (short‑term, working, long‑term retrieval)
• Perception and motor (visual, auditory, sensorimotor tasks)
• Social and emotional understanding (theory of mind, affect recognition)
• Creativity and generativity (novel idea production, divergent thinking)


Each domain is operationalised with validated item banks and task families to ensure content validity.

Measurement framework

Yook uses established measurement science: item response theory, differential item functioning (DIF) audits, versioned norms, and sample‑size calibration. Tests are administered via reproducible pipelines with open data and code for scoring, so results are replicable. Confidence intervals and uncertainty estimates accompany every reported sub‑score and overall Yk.

Governance and safeguards

Yook includes governance annexes to prevent misuse: explicit prohibitions on using Yk for individual psychological diagnosis, hiring decisions, or discriminatory profiling. The standard requires transparent documentation, provenance metadata, and independent audit trails. Versioning and timestamped norms prevent cherry‑picked comparisons across model versions.

Reporting and interpretation

Reports include: domain sub‑scores with CIs, the overall Yk, test conditions (prompting, compute, dataset), and provenance (test version, seed, evaluator). Suggested public phrasing and machine‑readable metadata make automated compliance and regulatory review feasible.

Use cases

• Research: consistent benchmarking across labs and model families.
• Industry: product claims that are auditable and comparable.
• Policy and regulation: a common language for assessing domain‑specific human parity.
• Education and assessment: mapping AI capabilities to human skill profiles.


Adoption roadmap

Start with a pilot item bank and open reference implementation, followed by multi‑site validation, public norms release, and standards body adoption. Collaboration across psychometrics, AI labs, regulators, and civil society is essential.

Key benefits and limits

Benefits: clearer consumer protection, better policy signals, and auditable claims. Limits: Yook measures performance on defined tasks and cannot capture every facet of human experience; it must be used alongside qualitative evaluation and domain‑specific safety assessments.

Closing

Yook turns vague capability claims into actionable, auditable metrics, enabling safer, clearer, and more responsible progress in AI.
